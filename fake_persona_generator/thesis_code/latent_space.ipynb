{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "import joblib\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = pd.read_csv(\"tutajDaneRzeczywiste\", sep=';')\n",
    "\n",
    "df = df.sample(n=300, replace=True)\n",
    "\n",
    "def map_values(df, columns_mappings):\n",
    "\n",
    "    df_new = df.copy()\n",
    "    for column, mapping in columns_mappings.items():\n",
    "        df_new[column] = df_new[column].replace(mapping)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "\n",
    "def scale_to_zero_one(df, scaler):\n",
    "    return pd.DataFrame(scaler.transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "def back_to_original_scale(df, scaler):\n",
    "    return pd.DataFrame(scaler.inverse_transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "def to_int(df, columns):\n",
    "\n",
    "    df_new = df.copy()\n",
    "    for col in columns:\n",
    "        df_new[col] = df_new[col].astype('int32')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Imię'] = df['Imię i Nazwisko'].apply(lambda x: x.split(' ')[0])\n",
    "df['Nazwisko'] = df['Imię i Nazwisko'].apply(lambda x: x.split(' ')[1])\n",
    "\n",
    "\n",
    "\n",
    "df.drop('Imię i Nazwisko', axis=1, inplace=True)\n",
    "df.drop('Sygnatura czasowa', axis=1, inplace=True)\n",
    "df.drop('E-mail', axis=1, inplace=True)\n",
    "\n",
    "df[\"Stanowisko *\"], stanowisko_mapping = pd.factorize(df[\"Stanowisko *\"])\n",
    "df[\"Imię\"], imie_mapping = pd.factorize(df[\"Imię\"])\n",
    "df[\"Nazwisko\"], nazwisko_mapping = pd.factorize(df[\"Nazwisko\"])\n",
    "\n",
    "stanowisko_mapping_dict = dict(enumerate(stanowisko_mapping))\n",
    "imie_mapping_dict = dict(enumerate(imie_mapping))\n",
    "nazwisko_mapping_dict = dict(enumerate(nazwisko_mapping))\n",
    "\n",
    "\n",
    "df_dataset = (\n",
    "    df.\n",
    "    pipe(to_int, columns = [\n",
    "        'Wiek *'\n",
    "])\n",
    ")\n",
    "df_dataset_num = (\n",
    "    df_dataset\n",
    "    .pipe(map_values, columns_mappings={\n",
    "        'Płeć': {'K': 1, 'M': 0}\n",
    "        })\n",
    ")\n",
    "\n",
    "scaler = MinMaxScaler().fit(df_dataset_num)\n",
    "df_dataset_scaled = scale_to_zero_one(df_dataset_num, scaler)\n",
    "df_dataset_scaled_back = back_to_original_scale(df_dataset_scaled, scaler)\n",
    "\n",
    "df['Stanowisko_original'] = df['Stanowisko *'].map(lambda x: stanowisko_mapping_dict[x])\n",
    "df['Imię_original'] = df['Imię'].map(lambda x: imie_mapping_dict[x])\n",
    "df['Nazwisko_original'] = df['Nazwisko'].map(lambda x: nazwisko_mapping_dict[x])\n",
    "\n",
    "display(df_dataset_scaled_back.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dist_matrix = pairwise_distances(df_dataset_scaled, metric='cosine')\n",
    "\n",
    "\n",
    "projected_data = MDS(n_components=2,\n",
    "                        dissimilarity='precomputed',\n",
    "                        normalized_stress='auto').fit_transform(Dist_matrix)\n",
    "\n",
    "df_dataset_latent = pd.DataFrame(projected_data, columns=['z1', 'z2'])\n",
    "Dist_matrix_proj = pairwise_distances(df_dataset_latent, metric='cosine')\n",
    "\n",
    "print()\n",
    "\n",
    "columns_list = [\n",
    "    'Imię', 'Nazwisko',\n",
    "    'Wiek *', 'Stanowisko *',\n",
    "    'Płeć'\n",
    "]\n",
    "\n",
    "df_dataset_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.008).fit(df_dataset_latent)\n",
    "\n",
    "joblib.dump(kde, 'kde.joblib')\n",
    "\n",
    "df_samples_latent = pd.DataFrame(kde.sample(len(df_dataset_scaled)), columns=df_dataset_latent.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoder(model, features, target, display=None):\n",
    "    \n",
    "    (features_train, features_test,\n",
    "     target_train, target_test) = train_test_split(features, target, test_size=0.8)\n",
    "\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    if display == 'cont':\n",
    "        pred_train = model.predict(features_train)\n",
    "        pred_test = model.predict(features_test)\n",
    "\n",
    "        fig, ax = plt.subplots(1,2, figsize=(6,3), sharey=True)\n",
    "        ax[0].scatter(target_train, pred_train, alpha=1, s=8, label='training data')\n",
    "        ax[0].axis('square')\n",
    "        ax[0].plot([0, 1], [0, 1], color='black', label='ideal')\n",
    "        ax[0].set_xlim([0,1])\n",
    "        ax[0].set_ylim([0,1])\n",
    "        ax[0].set_xlabel('target')\n",
    "        ax[0].set_ylabel('prediction')\n",
    "        ax[0].legend()\n",
    "        ax[1].scatter(target_test, pred_test, alpha=0.5, s=8, label='testing data')\n",
    "        ax[1].axis('square')\n",
    "        ax[1].plot([0, 1], [0, 1], color='black', label='ideal')\n",
    "        ax[1].set_xlim([0,1])\n",
    "        ax[1].set_ylim([0,1])\n",
    "        ax[1].set_xlabel('target')\n",
    "        fig.suptitle(target.name)\n",
    "        ax[1].legend()\n",
    "        plt.show()\n",
    "        \n",
    "    elif display == 'cat':\n",
    "        pred_train = model.predict(features_train)\n",
    "        pred_test = model.predict(features_test)\n",
    "\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        cm = confusion_matrix(target_test, pred_test, labels=np.unique(target_test))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=np.unique(target_test))\n",
    "        ax.set_title(target.name)\n",
    "        disp.plot(ax=ax)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def make_decoders(df_latent, df_target, cont_columns, cat_columns, display=False):\n",
    "\n",
    "    decoders = {}\n",
    "\n",
    "    for col in cont_columns:\n",
    "        target = df_target[col]\n",
    "        a = df_target[col].to_list()\n",
    "        decoders[col] = make_decoder(\n",
    "            model=RandomForestRegressor(),\n",
    "            features=df_latent,\n",
    "            target=target,\n",
    "            display='cont' if display else None\n",
    "            )\n",
    "        \n",
    "    for col in cat_columns:\n",
    "        target = df_target[col]\n",
    "        f = target.to_list()\n",
    "        decoders[col] = make_decoder(\n",
    "            model=SVC(),\n",
    "            features=df_latent,\n",
    "            target= round(target),\n",
    "            display='cat' if display else None\n",
    "            )\n",
    "        \n",
    "        print(f\"target: {col} -> \", target)\n",
    "\n",
    "    return decoders\n",
    "\n",
    "a = make_decoders(\n",
    "    df_latent=df_dataset_latent, \n",
    "    df_target=df_dataset_scaled, \n",
    "    cont_columns=['Wiek *','Imię', 'Nazwisko',  'Stanowisko *'],\n",
    "    cat_columns= ['Płeć'],\n",
    "    display=True\n",
    ")\n",
    "\n",
    "\n",
    "for key, value in a.items():\n",
    "    joblib.dump(value, 'TrainedModels/'+f'{key.split(' ')[0]}_{value.__class__.__name__}_trained.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_rows(df):\n",
    "    return [pd.DataFrame(row).T for index, row in df.iterrows()]\n",
    "\n",
    "def decode_sample(sample):\n",
    "    return {col: decoder.predict(sample) for col, decoder in a.items()}\n",
    "\n",
    "samples_latent = df_to_rows(df_samples_latent)\n",
    "df_decoded_samples = pd.DataFrame([decode_sample(sample) for sample in samples_latent], columns=df_dataset.columns)\n",
    "\n",
    "df_synthetic_raw = back_to_original_scale(df_decoded_samples, scaler)\n",
    "\n",
    "def round_to_2sd(df, columns):\n",
    "\n",
    "    df_new = df.copy()\n",
    "    for col in columns:\n",
    "        df_new[col] = df_new[col].apply(lambda value: round(value, 2))\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "\n",
    "def round_to_1sd(df, columns):\n",
    "\n",
    "    df_new = df.copy()\n",
    "    for col in columns:\n",
    "        df_new[col] = df_new[col].apply(lambda value: round(value, 1))\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "\n",
    "df_synthetic_num = (\n",
    "    df_synthetic_raw.\n",
    "    pipe(to_int, columns=[\n",
    "        'Wiek *'])\n",
    ")\n",
    "\n",
    "df_synthetic = (\n",
    "    df_synthetic_num.\n",
    "    pipe(map_values, columns_mappings={\n",
    "        'Płeć': {1: 'Female', 0: 'Male'},\n",
    "        })\n",
    ")\n",
    "\n",
    "df['Stanowisko_original'] = df['Stanowisko *'].map(lambda x: stanowisko_mapping_dict[x])\n",
    "df['Imię_original'] = df['Imię'].map(lambda x: imie_mapping_dict[x])\n",
    "df['Nazwisko_original'] = df['Nazwisko'].map(lambda x: nazwisko_mapping_dict[x])\n",
    "\n",
    "\n",
    "df_synthetic_raw_scaled = df_synthetic_raw.copy()\n",
    "\n",
    "columns_to_scale = ['Płeć','Stanowisko *', 'Imię', 'Nazwisko']\n",
    "\n",
    "\n",
    "def min_max_scaling(column):\n",
    "    return ((column - column.min()) / (column.max() - column.min()) * column.max()).round().astype(int)\n",
    "\n",
    "df_synthetic_raw_scaled[columns_to_scale] = df_synthetic_raw_scaled[columns_to_scale].apply(min_max_scaling)\n",
    "\n",
    "df_synthetic_raw_scaled\n",
    "\n",
    "df_syntehtic_mapped = df_synthetic_raw.copy()\n",
    "\n",
    "\n",
    "\n",
    "df_syntehtic_mapped['Stanowisko *'] = df_synthetic_raw_scaled['Stanowisko *'].map(lambda x: stanowisko_mapping_dict[x])\n",
    "df_syntehtic_mapped['Imię'] = df_synthetic_raw_scaled['Imię'].map(lambda x: imie_mapping_dict[x])\n",
    "df_syntehtic_mapped['Nazwisko'] = df_synthetic_raw_scaled['Nazwisko'].map(lambda x: nazwisko_mapping_dict[x])\n",
    "\n",
    "df_syntehtic_mapped['Wiek *'] = df_syntehtic_mapped['Wiek *'].map(lambda x: int(round(x)))\n",
    "df_syntehtic_mapped['Płeć'] = df_syntehtic_mapped['Wiek *'].map(lambda x: int(round(x)))\n",
    "\n",
    "\n",
    "df_syntehtic_mapped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from table_evaluator import load_data, TableEvaluator\n",
    "table_evaluator = TableEvaluator(df_dataset, df_synthetic)\n",
    "\n",
    "\n",
    "\n",
    "table_evaluator.visual_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
